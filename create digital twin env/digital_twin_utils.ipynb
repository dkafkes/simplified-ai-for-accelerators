{"cells":[{"cell_type":"code","source":["#Rachael's/PID Eq-- questions about whether this actually covers the full dynamics\n\n#might have to update these values?\nalpha = 10e-2\ngamma = 7.535e-5\n\ndef regulation(df, alpha=10e-2, gamma=7.535e-5):\n  ## calculate the prediction with current regulation rules\n  ## from Rachael's report, eq (1)\n  beta=[0]\n  ER = df[\"B:IMINER\"].astype('float') #error\n  _MIN = df[\"B_VIMIN\"].astype('float') #setting\n  for i in range(len(_MIN)):\n      if i>0:\n          beta_t = beta[-1] + gamma*ER[i]\n          beta.append(beta_t)\n  MIN_pred = _MIN - alpha * ER - beta #predict the next, shiftting happens in the plotting\n  return MIN_pred"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0a1dd40e-dc03-4d61-ac0d-28abd16f34c1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def scale(df, var_list = ['B:VIMIN', 'B:IMINER', 'B_VIMIN', 'B:LINFRQ', 'B:ACMNIG', 'B:ACMNPG', 'I:IB', 'I:MDAT40']):\n  scale_dict = {}\n\n  for var in var_list:\n  #for var in ['B:ACMNIG', 'B:ACMNPG']:\n    our_data2 = df\n    trace = our_data2[var].astype('float32')\n    data = np.array(trace)\n    median = np.median(data)\n    upper_quartile = np.percentile(data, 75)\n    lower_quartile = np.percentile(data, 25)\n\n    iqr = upper_quartile - lower_quartile\n    lower_whisker = data[data>=lower_quartile-1.5*iqr].min()\n    upper_whisker = data[data<=upper_quartile+1.5*iqr].max()\n\n    if var == 'B:ACMNPG':\n      median = 9.1968\n      upper_whisker = median + 0.75*0.674\n      lower_whisker = median - 0.75*0.674\n    elif var == 'B:ACMNIG':\n      upper_whisker = 0.75350088\n      lower_whisker = 0\n\n    print(f'Variable {var} with upper {upper_whisker} and lower {lower_whisker}')\n\n    ranged = upper_whisker - lower_whisker\n    #(value âˆ’ median) / (upper - lower)\n\n    our_data2[var] = 1/ranged*(data - median)\n\n    scale_dict[str(var)] = {\"median\": median, \"range\": ranged}\n  # print(scale_dict)\n\n  return(our_data2, scale_dict)\n\n#need this for all the plotting functions\ndef unscale(var_name, tseries, scale_dict):\n  from_model = np.asarray(tseries)\n  update = from_model*scale_dict[str(var_name)][\"range\"] + scale_dict[str(var_name)][\"median\"]\n  return(update)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f2863c19-9e1f-4e9e-b9df-326b00015092"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# we moved away from using these scalers since it's difficult to implement them in C++ on the board\n#from sklearn.preprocessing import MinMaxScaler, RobustScaler\n\ndef create_dataset(dataset, look_back=1,look_forward=1):\n    X, Y = [], []\n    offset = look_back+look_forward\n    for i in range(len(dataset)-(offset+1)):\n        xx = dataset[i:(i+look_back), 0]\n        yy = dataset[(i + look_back):(i + offset), 0]\n        X.append(xx)\n        Y.append(yy)\n    return np.array(X), np.array(Y)\n\ndef get_dataset(data, variable='B:VIMIN'):\n    df = data\n    dataset = df[variable].values #numpy.ndarray\n    dataset = dataset.astype('float32')\n    dataset = np.reshape(dataset, (-1, 1))\n#     scaler = MinMaxScaler(feature_range=(0, 1)) #i'm going to keep saving the minmax scaler just so i don't have to update a lot of things\n    #2/28: jokes not changing this yet... need to know how malachi wants me to implement the inverse scaling\n    #scaler = RobustScaler()\n#     dataset = scaler.fit_transform(dataset)\n\n    ## TODO: Fix\n    #print(len(dataset))\n    train_size = int(len(dataset) * 0.70)\n    #print(train_size)\n    test_size = len(dataset) - train_size\n    #print(test_size)\n\n    train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n\n    X_train, Y_train = create_dataset(train, look_back,look_forward)\n    X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n    Y_train = np.reshape(Y_train, (Y_train.shape[0],  Y_train.shape[1]))\n    #print(X_train.shape)\n    #print(Y_train.shape)\n    \n    X_test, Y_test = create_dataset(test, look_back,look_forward)\n    X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n    Y_test = np.reshape(Y_test, (Y_test.shape[0],  Y_test.shape[1]))\n    #print(X_test.shape)\n    #print(Y_test.shape)\n#     return scaler, X_train, Y_train, X_test, Y_test\n    return X_train, Y_train, X_test, Y_test\n  #reminder that we've changed the scaler so there are different indices now: return X_train, Y_train, X_test, Y_test but no scaler"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d363569c-50fc-437c-9116-f272d161cc37"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def loss_plot(fold, histories, model, BoX_test, BoY_test):\n  \n  if fold == 4:\n    print(histories[0].history['loss'])\n    print(histories[1].history['loss'])\n    print(histories[2].history['loss'])\n    print(histories[3].history['loss'])\n    print(histories[4].history['loss'])\n    \n    loss_trace = []\n    vloss_trace = []\n    \n    for k in range(5):\n        #print(k)\n        #print(k)\n        #print(histories[k])\n        fold_histories = np.array(histories[k].history['loss'])\n        #print(fold_histories.shape)\n        loss_trace.append(fold_histories)\n        vloss_trace.append(np.array(histories[k].history['val_loss']))\n\n        full_loss_trace = np.concatenate(loss_trace)\n        full_vloss_trace = np.concatenate(vloss_trace)\n        #print(full_loss_trace.shape)\n        \n    plt.figure(figsize=(12,10))\n    plt.plot(full_loss_trace, label='loss')\n    plt.plot(full_vloss_trace, label='val_loss')\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epochs')\n    plt.legend(loc='upper right')\n    plt.yscale('log')\n\n    plt.savefig('loss_{}.png'.format(fold))\n    mlflow.log_artifact('loss_{}.png'.format(fold))\n\n    dump(full_loss_trace, open('/tmp/'+timestamp+'_'+'full_loss.pkl', 'wb')) \n    temp_path_scaler = 'file:/tmp/'+timestamp+'_'+'full_loss.pkl'\n    final_path_scaler = 'dbfs:/FileStore/models/'+timestamp+'/full_loss.pkl'\n    dbutils.fs.cp(temp_path_scaler, final_path_scaler)\n      \n    dump(full_vloss_trace, open('/tmp/'+timestamp+'_'+'full_vloss.pkl', 'wb')) \n    temp_path_scaler = 'file:/tmp/'+timestamp+'_'+'full_vloss.pkl'\n    final_path_scaler = 'dbfs:/FileStore/models/'+timestamp+'/full_vloss.pkl'\n    dbutils.fs.cp(temp_path_scaler, final_path_scaler)\n  \n  #print(np.array(vloss_trace).flatten())\n  \n  #print(full_loss_trace)\n  #print(full_vloss_trace)\n\n\n  #new_path = '/dbfs/FileStore/models/'+timestamp+'/'\n\n  #plt.savefig('{}loss_{}.png'.format(new_path, save_name))  \n  #plot_test(model,BoX_test,BoY_test,nvar=2,start=0,end=5000, name= 'loss.png') #) #.format(new_path, save_name))\n  \n  #def plot_test(model,x_test,y_test,nvar=2,name='test',start=0,end=500):\n  start = 0\n  end = 5000\n  nvar = 2\n  \n  Y_predict = model.predict(BoX_test[start:end,:,:])\n  #print(Y_predict.shape)\n  fig, axs = plt.subplots(nvar,figsize=(14,12))\n  \n  for v in range (nvar):\n      Y_test_var1 = BoY_test[start:end,v].reshape(-1,1)\n      Y_predict_var1 = Y_predict[:,v].reshape(-1,1)\n      axs[v].plot(Y_test_var1,label='Data')\n      axs[v].plot(Y_predict_var1, label='Prediction')\n        \n  plt.savefig('predict_{}.png'.format(fold))\n  mlflow.log_artifact('predict_{}.png'.format(fold))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9743a878-dafc-4fb4-b19a-7359831e1ab1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def predict_plot(fold, model, BoX_test, BoY_test):\n  import seaborn as sns\n  #model=booster_model\n  x_test=BoX_test\n  y_test=BoY_test\n  nvar=2\n  name='test_diff'\n  start=0\n  end=1000\n  x = np.linspace(start,end,int(end-start))\n  Y_predict = model.predict(x_test[start:end,:,:])\n  #print(Y_predict.shape)\n  fig, axs = plt.subplots(nvar,figsize=(16,16))\n  \n  vnames = variables[0:nvar] #should be names\n  \n  for v in range(nvar):\n      Y_test_var1 = unscale(str(vnames[v]), y_test[start:end,v].reshape(-1,1), scale_dict)\n      Y_predict_var1 = unscale(str(vnames[v]), Y_predict[:,v].reshape(-1,1), scale_dict)\n    \n#       no more scaler\n#       Y_test_var1 = data_list[v][0].inverse_transform(y_test[start:end,v].reshape(-1,1))\n#       Y_predict_var1 = data_list[v][0].inverse_transform(Y_predict[:,v].reshape(-1,1))\n      \n      #axs[v].plot(Y_test_var1,Y_predict_var1,'o')\n      mape = 100*abs(Y_test_var1-Y_predict_var1)/Y_test_var1\n      #print(x.shape)\n      #print(mape.shape)\n      mape = mape.reshape(-1,)\n      #print(mape.shape)\n      #print('mape ave:{}'.format(mape.mean()))\n      axs[v].plot(Y_test_var1,label='Data')\n      axs[v].plot(Y_predict_var1, label='Digital Twin')\n      #axs[v].fill_between(x, mape, -mape, color='red',edgecolor=\"black\",alpha=0.5) \n      #axs[v].plot(mape)\n      #axs[v].set_title(variables[v])\n      axs[v].set_ylabel(variables[v])\n      axs[v].set_xlabel('Time samples')\n      axs[v].legend()\n\n  #plt.savefig('/dbfs/FileStore/models/'+timestamp+'/'+mcp_name+'_prediction_final.png')\n  plt.savefig(\"prediction_{}.png\".format(fold))\n  mlflow.log_artifact(\"prediction_{}.png\".format(fold))\n\n  # plt.savefig('{}.png'.format(name))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5bb4115-2115-4ff6-8f09-7cddd8a11229"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def data_distribution_plot(fold, model, BoX_test, BoY_test, scale_dict):\n  import seaborn as sns\n  fig, axs = plt.subplots(1,figsize=(12,12))\n  x_test=BoX_test\n  y_test=BoY_test\n  start=0\n  end=BoX_test.shape[0]\n  Y_predict = model.predict(x_test[start:end,:,:])\n  \n  #indices from ['B:VIMIN', 'B:IMINER', 'B_VIMIN', 'B:LINFRQ', 'B:ACMNIG', 'B:ACMNPG', 'I:IB', 'I:MDAT40']\n\n  # 0 is B:VIMIN\n  # 1 is B:IMINER\n  # 2 is B_VIMIN\n  # 3 is B:LINFRQ\n  # 4 is B:ACMNIG\n  # 5 is B:ACMNPG\n  # 6 is I:IB\n  # 7 is I:MDAT40\n  \n  Y_test_var0 = unscale(str(variables[0]), y_test[start:end,0].reshape(-1,1), scale_dict).reshape(-1,1)\n  Y_test_var1 = unscale(str(variables[1]), y_test[start:end,1].reshape(-1,1), scale_dict).reshape(-1,1)\n  \n  Y_predict_var0 = unscale(str(variables[0]), Y_predict[:,0].reshape(-1,1), scale_dict).reshape(-1,1)\n  Y_predict_var1 = unscale(str(variables[1]), Y_predict[:,1].reshape(-1,1), scale_dict).reshape(-1,1)\n  \n  x_bvimin = unscale(str(variables[0]), x_test[start:end,0,-1].reshape(-1,1), scale_dict).reshape(-1,1)\n  x_biminer = unscale(str(variables[1]), x_test[start:end,1,-1].reshape(-1,1), scale_dict).reshape(-1,1)\n  x_b_vimin = unscale(str(variables[2]), x_test[start:end,2,-1].reshape(-1,1), scale_dict).reshape(-1,1)\n\n#   Y_test_var0 = data_list[0][0].inverse_transform(y_test[start:end,0].reshape(-1,1)).reshape(-1,1)\n#   Y_test_var1 = data_list[1][0].inverse_transform(y_test[start:end,1].reshape(-1,1)).reshape(-1,1)\n  \n#   Y_predict_var0 = data_list[0][0].inverse_transform(Y_predict[:,0].reshape(-1,1)).reshape(-1,1)\n#   Y_predict_var1 = data_list[1][0].inverse_transform(Y_predict[:,1].reshape(-1,1)).reshape(-1,1)\n  \n#   x_bvimin = data_list[0][0].inverse_transform(x_test[start:end,0,-1].reshape(-1,1)).reshape(-1,1) # data B:VIMIN\n#   x_biminer = data_list[1][0].inverse_transform(x_test[start:end,1,-1].reshape(-1,1)).reshape(-1,1) # data B:IMINER\n#   x_b_vimin = data_list[2][0].inverse_transform(x_test[start:end,2,-1].reshape(-1,1)).reshape(-1,1) # data B_VIMIN\n\n  #Rachael's/PID Eq\n  \n  # early March 2021, Kiyomi told me alpha =.01*B:ACMNPG and gamma = .00001*B:ACMNIG\n  x_alpha = .01*unscale(str(variables[5]), x_test[start:end,5,-1].reshape(-1,1), scale_dict).reshape(-1,1)\n  x_gamma = .00001*unscale(str(variables[4]), x_test[start:end,4,-1].reshape(-1,1), scale_dict).reshape(-1,1)\n \n  alpha = x_alpha #10e-2\n  gamma = x_gamma #7.535e-5\n  beta=[0]\n  for i in range(len(x_b_vimin)):\n      if i>0:\n          beta_t = beta[-1] + gamma[i]*x_biminer[i]\n          beta.append(beta_t[0])\n  \n#   print(x_b_vimin.shape)\n#   print(x_biminer.shape)\n#   print(np.asarray(beta).reshape(-1,1).shape)\n  \n  beta = np.asarray(beta).reshape(-1,1)\n  BVIMIN_rach = x_b_vimin -1*alpha*x_biminer -1*beta #predict the next, shiftting happens in the plotting\n  print(BVIMIN_rach)\n\n  BIMINER_rach = 10*np.add(x_b_vimin, -1*BVIMIN_rach)\n#   print(BIMINER_rach)\n#   print(x_biminer.shape)\n#   print(x_b_vimin.shape)\n#   print(BVIMIN_rach.shape)\n#   print(BIMINER_rach.shape)\n  \n#   BVIMIN_rach = BVIMIN_rach.reshape(BVIMIN_rach.shape[0],1)\n#   BIMINER_rach = BIMINER_rach.reshape(BIMINER_rach.shape[0],1)\n  \n#   print(Y_test_var0.shape)\n#   print(Y_test_var1.shape)\n#   print(Y_predict_var0.shape)\n#   print(Y_predict_var1.shape)\n\n  predicted = np.concatenate((Y_test_var0,Y_test_var1,Y_predict_var0,Y_predict_var1, BVIMIN_rach, BIMINER_rach),axis=concate_axis)\n#   print(predicted.shape)\n  df_cool = pd.DataFrame(predicted,columns=['data B:VIMIN','data B:IMINER','pred B:VIMIN','pred B:IMINER', 'PID B:VIMIN', 'PID B:IMINER'])\n#   print(df_cool.shape)\n  #sns.pairplot(df_predict)\n  #np_data = np.concatenate((Y_predict_var0,Y_predict_var1),axis=concate_axis) \n  #df_data = pd.DataFrame(np_data)\n  #sns.pairplot(df_data)\n  sns.scatterplot(data=df_cool, x=\"data B:VIMIN\", y=\"data B:IMINER\", label='Data') #, hue=\"time\")\n  sns.scatterplot(data=df_cool, x=\"pred B:VIMIN\", y=\"pred B:IMINER\", label='Digital Twin') #, hue=\"time\")\n  sns.scatterplot(data=df_cool, x=\"PID B:VIMIN\", y=\"PID B:IMINER\", label=\"PID Eq\")\n\n  #sns.scatterplot(data=df_cool, x=\"data_va1\", y=\"pred_va1\", label='Data')#, hue=\"time\")\n\n  #axs.plot(Y_test_var0,Y_test_var1,'o', label='Data')\n  #axs.plot(Y_predict_var0,Y_predict_var1,'*', label='Digital Twin')\n  #axs.set_xlabel('B:VIMIN')\n  #axs.set_ylabel('B:IMINER')\n  #axs.set_xlim(103.2,103.6)\n  \n  #plt.savefig('/dbfs/FileStore/models/'+timestamp+'/'+mcp_name+'_corr_final.png')\n  plt.savefig(\"corr_{}.png\".format(fold))\n  mlflow.log_artifact(\"corr_{}.png\".format(fold))\n  \n  #plt.legend()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d53c8e5c-cd4d-4f01-ae46-6c0c7fa4268f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def statespace_distribution_plot(fold, model, BoX_test, BoY_test):\n  import seaborn as sns\n  fig, axs = plt.subplots(1,figsize=(12,12))\n  x_test=BoX_test\n  y_test=BoY_test\n  start=0\n  end=BoX_test.shape[0]\n  Y_predict = model.predict(x_test[start:end,:,:])\n  \n  Y_test_var0 = unscale(str(variables[0]), y_test[start:end,0].reshape(-1,1), scale_dict).reshape(-1,1)\n  Y_test_var1 = unscale(str(variables[1]), y_test[start:end,1].reshape(-1,1), scale_dict).reshape(-1,1)\n  \n  Y_predict_var0 = unscale(str(variables[0]), Y_predict[:,0].reshape(-1,1), scale_dict).reshape(-1,1)\n  Y_predict_var1 = unscale(str(variables[1]), Y_predict[:,1].reshape(-1,1), scale_dict).reshape(-1,1)\n  \n  x_bvimin = unscale(str(variables[0]), x_test[start:end,0,-1].reshape(-1,1), scale_dict).reshape(-1,1)\n  x_biminer = unscale(str(variables[1]), x_test[start:end,1,-1].reshape(-1,1), scale_dict).reshape(-1,1)\n  x_b_vimin = unscale(str(variables[2]), x_test[start:end,2,-1].reshape(-1,1), scale_dict).reshape(-1,1)\n  \n#   Y_test_var0 = data_list[0][0].inverse_transform(y_test[start:end,0].reshape(-1,1)).reshape(-1,1)\n#   Y_test_var1 = data_list[1][0].inverse_transform(y_test[start:end,1].reshape(-1,1)).reshape(-1,1)\n  \n#   Y_predict_var0 = data_list[0][0].inverse_transform(Y_predict[:,0].reshape(-1,1)).reshape(-1,1)\n#   Y_predict_var1 = data_list[1][0].inverse_transform(Y_predict[:,1].reshape(-1,1)).reshape(-1,1)\n  \n#   x_bvimin = data_list[0][0].inverse_transform(x_test[start:end,0,-1].reshape(-1,1)).reshape(-1,1) # data B:VIMIN\n#   x_biminer = data_list[1][0].inverse_transform(x_test[start:end,1,-1].reshape(-1,1)).reshape(-1,1) # data B:IMINER\n#   x_b_vimin = data_list[2][0].inverse_transform(x_test[start:end,2,-1].reshape(-1,1)).reshape(-1,1) # data B_VIMIN\n\n# early March 2021, Kiyomi told me alpha =.01*B:ACMNPG and gamma = .00001*B:ACMNIG\n  x_alpha = .01*unscale(str(variables[5]), x_test[start:end,5,-1].reshape(-1,1), scale_dict).reshape(-1,1)\n  x_gamma = .00001*unscale(str(variables[4]), x_test[start:end,4,-1].reshape(-1,1), scale_dict).reshape(-1,1)\n \n  alpha = x_alpha #10e-2\n  gamma = x_gamma #7.535e-5\n  beta=[0]\n  for i in range(len(x_b_vimin)):\n      if i>0:\n          beta_t = beta[-1] + gamma[i]*x_biminer[i]\n          beta.append(beta_t[0])\n  \n#   print(x_b_vimin.shape)\n#   print(x_biminer.shape)\n#   print(np.asarray(beta).reshape(-1,1).shape)\n  \n  beta = np.asarray(beta).reshape(-1,1)\n  BVIMIN_rach = x_b_vimin -1*alpha*x_biminer -1*beta #predict the next, shiftting happens in the plotting\n  BIMINER_rach = 10*np.add(x_b_vimin, -1*BVIMIN_rach)\n  \n# #   print(BIMINER_rach)\n# #   print(x_biminer.shape)\n# #   print(x_b_vimin.shape)\n# #   print(BVIMIN_rach.shape)\n# #   print(BIMINER_rach.shape)\n  \n# #   BVIMIN_rach = BVIMIN_rach.reshape(BVIMIN_rach.shape[0],1)\n# #   BIMINER_rach = BIMINER_rach.reshape(BIMINER_rach.shape[0],1)\n  \n# #   print(Y_test_var0.shape)\n# #   print(Y_test_var1.shape)\n# #   print(Y_predict_var0.shape)\n# #   print(Y_predict_var1.shape)\n\n  predicted = np.concatenate((Y_test_var0,Y_test_var1,Y_predict_var0,Y_predict_var1, BVIMIN_rach, BIMINER_rach),axis=concate_axis)\n#   print(predicted.shape)\n  df_cool = pd.DataFrame(predicted,columns=['data B:VIMIN','data B:IMINER','pred B:VIMIN','pred B:IMINER', 'PID B:VIMIN', 'PID B:IMINER'])\n  df_cool = df_cool.diff()\n#   print(df_cool.diff())\n  #sns.pairplot(df_predict)\n  #np_data = np.concatenate((Y_predict_var0,Y_predict_var1),axis=concate_axis) \n  #df_data = pd.DataFrame(np_data)\n  #sns.pairplot(df_data)\n  sns.scatterplot(data=df_cool, x=\"data B:VIMIN\", y=\"data B:IMINER\", label='Data Diff') #, hue=\"time\")\n  sns.scatterplot(data=df_cool, x=\"pred B:VIMIN\", y=\"pred B:IMINER\", label='Digital Twin Diff') #, hue=\"time\")\n  sns.scatterplot(data=df_cool, x=\"PID B:VIMIN\", y=\"PID B:IMINER\", label=\"PID Eq Diff\")\n\n  #sns.scatterplot(data=df_cool, x=\"data_va1\", y=\"pred_va1\", label='Data')#, hue=\"time\")\n\n  #axs.plot(Y_test_var0,Y_test_var1,'o', label='Data')\n  #axs.plot(Y_predict_var0,Y_predict_var1,'*', label='Digital Twin')\n  #axs.set_xlabel('B:VIMIN')\n  #axs.set_ylabel('B:IMINER')\n  #axs.set_xlim(103.2,103.6)\n  \n  #plt.savefig('/dbfs/FileStore/models/'+timestamp+'/'+mcp_name+'_corr_final.png')\n  plt.savefig(\"statespace_corr_{}.png\".format(fold))\n  mlflow.log_artifact(\"statespace_corr_{}.png\".format(fold))\n  \n  #plt.legend()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b435c4cf-dfd5-4533-9dda-bc30bf57e868"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def data_heatmap(fold, model, BoX_test, BoY_test):\n\n  import matplotlib.pyplot as plt\n  from mpl_toolkits.axes_grid1 import make_axes_locatable\n  import numpy as np\n\n  x_test=BoX_test\n  y_test=BoY_test\n  start=0\n  end=BoX_test.shape[0]\n  Y_predict = model.predict(x_test[start:end,:,:])\n  \n  Y_test_var0 = unscale(str(variables[0]), y_test[start:end,0].reshape(-1,1), scale_dict).reshape(-1,1)\n  Y_test_var1 = unscale(str(variables[1]), y_test[start:end,1].reshape(-1,1), scale_dict).reshape(-1,1)\n  \n  Y_predict_var0 = unscale(str(variables[0]), Y_predict[:,0].reshape(-1,1), scale_dict).reshape(-1,1)\n  Y_predict_var1 = unscale(str(variables[1]), Y_predict[:,1].reshape(-1,1), scale_dict).reshape(-1,1)\n  \n  x_bvimin = unscale(str(variables[0]), x_test[start:end,0,-1].reshape(-1,1), scale_dict).reshape(-1,1)\n  x_biminer = unscale(str(variables[1]), x_test[start:end,1,-1].reshape(-1,1), scale_dict).reshape(-1,1)\n  x_b_vimin = unscale(str(variables[2]), x_test[start:end,2,-1].reshape(-1,1), scale_dict).reshape(-1,1)\n  \n#   Y_test_var0 = data_list[0][0].inverse_transform(y_test[start:end,0].reshape(-1,1)).reshape(-1,1)\n#   Y_test_var1 = data_list[1][0].inverse_transform(y_test[start:end,1].reshape(-1,1)).reshape(-1,1)\n\n#   Y_predict_var0 = data_list[0][0].inverse_transform(Y_predict[:,0].reshape(-1,1)).reshape(-1,1)\n#   Y_predict_var1 = data_list[1][0].inverse_transform(Y_predict[:,1].reshape(-1,1)).reshape(-1,1)\n\n#   x_bvimin = data_list[0][0].inverse_transform(x_test[start:end,0,-1].reshape(-1,1)).reshape(-1,1) # data B:VIMIN\n#   x_biminer = data_list[1][0].inverse_transform(x_test[start:end,1,-1].reshape(-1,1)).reshape(-1,1) # data B:IMINER\n#   x_b_vimin = data_list[2][0].inverse_transform(x_test[start:end,2,-1].reshape(-1,1)).reshape(-1,1) # data B_VIMIN\n\n  # early March 2021, Kiyomi told me alpha =.01*B:ACMNPG and gamma = .00001*B:ACMNIG\n  x_alpha = .01*unscale(str(variables[5]), x_test[start:end,5,-1].reshape(-1,1), scale_dict).reshape(-1,1)\n  x_gamma = .00001*unscale(str(variables[4]), x_test[start:end,4,-1].reshape(-1,1), scale_dict).reshape(-1,1)\n \n  alpha = x_alpha #10e-2\n  gamma = x_gamma #7.535e-5\n  beta=[0]\n  for i in range(len(x_b_vimin)):\n      if i>0:\n          beta_t = beta[-1] + gamma[i]*x_biminer[i]\n          beta.append(beta_t[0])\n\n  #   print(x_b_vimin.shape)\n  #   print(x_biminer.shape)\n  #   print(np.asarray(beta).reshape(-1,1).shape)\n\n  beta = np.asarray(beta).reshape(-1,1)\n  BVIMIN_rach = x_b_vimin -1*alpha*x_biminer -1*beta #predict the next, shiftting happens in the plotting\n  BIMINER_rach = 10*np.add(x_b_vimin, -1*BVIMIN_rach)\n\n  #   print(BVIMIN_rach)\n\n  #print(Y_test_var0)\n  #print(BIMINER_rach)\n\n  predicted = np.concatenate((Y_test_var0,Y_test_var1,Y_predict_var0,Y_predict_var1, BVIMIN_rach, BIMINER_rach),axis=concate_axis)\n  df_cool = pd.DataFrame(predicted,columns=['data B:VIMIN','data B:IMINER','pred B:VIMIN','pred B:IMINER', 'PID B:VIMIN', 'PID B:IMINER'])\n\n  #df_cool.head(10)\n  # #x is B:VIMIN\n  # #y is B:IMINER\n\n  # # Generate some test data\n  x = np.asarray(df_cool['data B:VIMIN'])\n  y = np.asarray(df_cool['data B:IMINER'])\n  heatmap, xedges, yedges = np.histogram2d(x, y, bins=[200,200], density=True, range = [[103.2, 103.6], [-.6, .6]])\n  \n#   print(min(x), max(x))\n\n  #print(xedges, yedges)\n  #extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n\n  # #print(extent)\n\n  x2 = np.asarray(df_cool['pred B:VIMIN'])\n  y2 = np.asarray(df_cool['pred B:IMINER'])\n  #   print(x2.shape)\n  #   print(y2.shape)\n  heatmap2, xedges2, yedges2 = np.histogram2d(x2, y2, bins=[200,200], density=True, range = [[103.2, 103.6], [-1, 1]])\n  # #extent2 = [xedges2[0], xedges2[-1], yedges2[0], yedges2[-1]]\n\n  #print(xedges2, yedges2)\n  # #print(extent2)\n\n  x3 = np.asarray(df_cool['PID B:VIMIN']) #.reshape(-1, )\n  y3 = np.asarray(df_cool['PID B:IMINER']) #.reshape(-1, )\n  #   print(x3.shape)\n  #   print(y3.shape)\n  heatmap3, xedges3, yedges3 = np.histogram2d(x3, y3, bins=[200,200], density=True, range = [[103.2, 103.6], [-1, 1]])\n  #extent3 = [xedges3[0], xedges3[-1], yedges3[0], yedges3[-1]]\n\n  #print(xedges3, yedges3)\n  #extent = [min(x), max(x)]\n\n  #sns.scatterplot(data=df_cool, x=\"data B:VIMIN\", y=\"data B:IMINER\", label='Data') #, hue=\"time\")\n\n  fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(15, 24))\n#   fig.tight_layout()\n  ax[0].set_title('Data')\n  a = ax[0].imshow(heatmap, interpolation='nearest', origin='lower', aspect='auto')\n  ax[1].set_title('Digital Twin')\n  b = ax[1].imshow(heatmap2, interpolation='nearest',origin='lower', aspect='auto')\n  ax[2].set_title('PID Eq')\n  c = ax[2].imshow(heatmap3, interpolation='nearest',origin='lower', aspect='auto')\n  #fig.subplots_adjust(hspace=-.05)\n  \n  i = 0\n  p = [a, b, c]\n  for ax in fig.get_axes():\n    ax.set_ylabel('B:IMINER')\n    ax.set_xlabel('B:VIMIN')  \n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", \"5%\", pad=\"3%\")\n    ax.figure.colorbar(p[i], cax=cax)\n    i+=1\n\n  plt.savefig(\"heatmap_{}.png\".format(fold))\n  mlflow.log_artifact(\"heatmap_{}.png\".format(fold))\n  #   plt.show()\n\n  #need to add colorbars too\n# data_heatmap(1, booster_model, BoX_test, BoY_test)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57356e88-f1db-4edd-936b-c13982c80746"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f61c0af-ee14-425b-9e59-4f2a31d632b4"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"digital_twin_utils","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":883897649962820}},"nbformat":4,"nbformat_minor":0}
